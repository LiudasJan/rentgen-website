<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <title>Boundary Value Analysis — the test technique everyone knows, and still forgets</title>
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="description" content="Rentgen includes Boundary Value Analysis out of the box. Import a cURL, set min/max once, and Rentgen generates the full boundary test set (including negative checks) automatically — no scripts, no ceremony." />
  <meta name="keywords" content="boundary value analysis, BVA testing, API testing, boundary testing, data-driven tests, negative testing, input validation, Rentgen, API quality, automated test generation" />
  <link rel="canonical" href="https://rentgen.io/api-stories/boundary-value-analysis.html" />

  <!-- Favicon -->
  <link rel="icon" type="image/x-icon" href="../assets/favicon.ico" />
  <link rel="icon" type="image/png" href="../assets/rentgen-logo.png" />
  <link rel="apple-touch-icon" href="../assets/rentgen-logo.png" />

  <!-- Open Graph / Social -->
  <meta property="og:title" content="Rentgen – Secure Local API Testing Tool" />
  <meta property="og:description" content="No cloud. No tracking. No logs. Just brutal API testing on your machine." />
  <meta property="og:image" content="https://rentgen.io/assets/og-image.png" />
  <meta property="og:url" content="https://rentgen.io/" />
  <meta property="og:type" content="website" />

  <meta name="twitter:card" content="summary_large_image" />
  <meta name="twitter:title" content="Rentgen – Secure Local API Testing Tool" />
  <meta name="twitter:description" content="No cloud. No tracking. No logs. Just brutal API testing on your machine." />
  <meta name="twitter:image" content="https://rentgen.io/assets/og-image.png" />

  <link rel="stylesheet" href="../styles.css" />
</head>

<body>
  <header class="site-header">
    <div class="container header-inner">
      <a href="https://rentgen.io/#top" class="brand">
        <img src="../assets/rentgen-logo.png" class="brand-logo" />
        <span class="brand-name">Rentgen</span>
      </a>
      <button class="nav-toggle" aria-label="Toggle navigation">
        <span></span><span></span>
      </button>
      <nav class="site-nav">
        <a href="https://rentgen.io/#features">Features</a>
        <a href="https://rentgen.io/#security">Security</a>
        <a href="https://rentgen.io/#downloads">Downloads</a>
        <a href="https://rentgen.io/#cases">Case studies</a>
        <a href="https://rentgen.io/#github">GitHub</a>
        <a href="https://rentgen.io/api-stories/">API Stories</a>
      </nav>
    </div>
  </header>

  <main class="section">
    <article class="container article">
      <header class="article-header">
        <h1>Boundary Value Analysis — the test technique everyone knows, and still forgets</h1>
        <p class="article-meta">Rentgen API Stories · January 2026</p>
      </header>

      <div class="article-content">
        <p>
          Boundary Value Analysis (BVA) is one of those testing techniques that feels so obvious,
          it almost becomes invisible.
        </p>

        <p>
          Everyone can explain it in one sentence:
          <em>systems break near the edges</em>.
        </p>

        <p>
          And yet, in real projects, it is still one of the most commonly skipped checks —
          not because teams don’t believe in it, but because it quietly becomes “extra work”.
        </p>

        <p>
          Rentgen exists for exactly that category of testing:
          the work that everyone agrees is important,
          but nobody wants to manually repeat for the 500th endpoint.
        </p>

        <figure>
          <img width="100%" src="../assets/api-stories/boundary-value-analysis.png" alt="Cache-Control for Private API in Rentgen" />
          <figcaption>Rentgen do boundary testing out of the box</figcaption>
        </figure>

        <h2>A quick bit of history (and why it still matters)</h2>

        <p>
          Boundary testing is older than most modern software stacks.
          It comes from the era when off-by-one errors weren’t just annoying —
          they were expensive, sometimes catastrophic, and extremely easy to ship.
        </p>

        <p>
          The lesson survived every generation of technology because human logic did not change:
          when developers implement validation, limits, ranges, and constraints,
          the mistakes cluster around the edges:
        </p>

        <ul>
          <li>min and max checks implemented inconsistently</li>
          <li>inclusive vs. exclusive boundaries misunderstood</li>
          <li>types converted too late (or not at all)</li>
          <li>overflow/underflow behavior ignored</li>
          <li>error handling returning success responses</li>
        </ul>

        <p>
          APIs are especially vulnerable because they are “just JSON” —
          which makes people assume validation is simple.
          It isn’t.
        </p>

        <h2>What this test is — and what it is not</h2>

        <p>
          Rentgen’s Boundary Value Analysis is not a replacement for deep domain testing.
          It will not invent business rules for you.
        </p>

        <p>
          What it <strong>will</strong> do is enforce the basic engineering contract:
          if your API claims a numeric field has a range,
          it must behave correctly at the edges —
          and it must reject values outside the range.
        </p>

        <h2>The “forgotten” reality of API testing tools</h2>

        <p>
          Traditional API clients are great at sending requests.
          They are not great at making you test properly.
        </p>

        <p>
          If you try to reproduce Rentgen’s boundary logic in a typical “API client → collections → assertions” workflow,
          you end up writing a mini test suite:
        </p>

        <ul>
          <li>at least 6–8 separate requests</li>
          <li>duplicate payloads with one field changed each time</li>
          <li>multiple assertions (2xx vs 4xx, response schema, error messages)</li>
          <li>a data-driven layer if you want to scale it</li>
          <li>maintenance overhead the moment the contract changes</li>
        </ul>

        <p>
          In practice, that means people do one request, see “200 OK”, and move on.
          The boundary tests “will be done later”.
          They often aren’t.
        </p>

        <h2>Rentgen makes it impossible to forget</h2>

        <p>
          Boundary Value Analysis in Rentgen is <strong>built in</strong>.
          Out of the box.
          No plugins.
          No scripts.
          No “we’ll add it later”.
        </p>

        <p>
          The workflow is intentionally small:
        </p>

        <ol>
          <li>Import a cURL</li>
          <li>Rentgen detects that a field is numeric</li>
          <li>You enter <strong>min</strong> and <strong>max</strong></li>
          <li>Rentgen generates and runs the boundary set automatically</li>
        </ol>

        <p>
          That’s it.
          You don’t spend time building the machinery.
          You spend time verifying the system.
        </p>

        <h2>What Rentgen actually does</h2>

        <p>
          When you provide the range (min/max), Rentgen executes a complete boundary test pack.
          The goal is to confirm two things:
        </p>

        <ul>
          <li>values inside the range behave as expected (success)</li>
          <li>values outside the range are rejected (client error)</li>
        </ul>

        <p>
          Concretely, Rentgen runs a set like this:
        </p>

        <ul>
          <li><strong>min</strong> → expects <strong>2xx</strong></li>
          <li><strong>min + 1</strong> → expects <strong>2xx</strong></li>
          <li><strong>random mid values</strong> → expects <strong>2xx</strong></li>
          <li><strong>max - 1</strong> → expects <strong>2xx</strong></li>
          <li><strong>max</strong> → expects <strong>2xx</strong></li>
          <li><strong>min - 1</strong> → expects <strong>4xx</strong> (negative check bonus)</li>
          <li><strong>max + 1</strong> → expects <strong>4xx</strong> (negative check bonus)</li>
        </ul>

        <p>
          That last part matters more than most teams admit.
          It’s not enough to “work inside the range”.
          The API must also prove it refuses invalid input.
        </p>

        <h2>What a real result looks like</h2>

        <p>
          Here is the kind of output you get — a clean data-driven table, where each row is a test,
          and the boundaries are impossible to miss:
        </p>

        <figure>
          <img width="100%" src="../assets/api-stories/boundary-value-analysis.png" alt="Boundary Value Analysis results table showing expected 2xx within range and expected 4xx outside range" />
          <figcaption>Boundary Value Analysis (data-driven) — inside values pass, outside values must fail</figcaption>
        </figure>

        <p>
          In the example above, values inside the range return <strong>200 OK</strong> as expected.
          But when the input crosses the boundary, the API still returns <strong>200 OK</strong>.
        </p>

        <p>
          That is not “a small bug”.
          That is the system telling you:
          <em>“I accept invalid input and pretend everything is fine.”</em>
        </p>

        <h2>Why this matters (beyond correctness)</h2>

        <p>
          Boundary failures are rarely isolated.
          When an API accepts invalid values, it usually creates one of these outcomes:
        </p>

        <ul>
          <li>data corruption in downstream systems</li>
          <li>unexpected behavior in calculations and aggregations</li>
          <li>security abuse (forcing edge cases to bypass logic)</li>
          <li>production incidents that look “random” but are input-driven</li>
          <li>expensive cleanup — because you can’t easily undo bad data</li>
        </ul>

        <p>
          And because boundaries are so simple, they are also one of the most efficient quality signals:
          a small check that catches disproportionately large risk.
        </p>

        <h2>Why most teams still skip it</h2>

        <p>
          Not because they don’t know the technique.
          They skip it because the tooling makes it feel like manual work.
        </p>

        <p>
          One endpoint is fine.
          Ten endpoints is annoying.
          A hundred endpoints is where everyone starts “prioritizing”.
        </p>

        <p>
          Rentgen removes the psychological barrier by removing the work.
          If BVA is built in, you run it —
          because not running it would be the weird choice.
        </p>

        <h2>The practical workflow</h2>

        <p>
          Boundary Value Analysis in Rentgen is a perfect “pre-test” check:
          run it early, on a single endpoint, before the API becomes a dependency chain.
        </p>

        <p>
          The fastest loop looks like this:
        </p>

        <ol>
          <li>Import cURL</li>
          <li>Set min/max for the numeric field</li>
          <li>Run BVA pack</li>
          <li>Export bug report with the failing rows attached</li>
        </ol>

        <p>
          No test suite scaffolding.
          No maintenance overhead.
          Just a clean signal: does the API enforce its own rules?
        </p>

        <h2>Final thoughts</h2>

        <p>
          Boundary Value Analysis is not a fancy technique.
          It’s a basic one.
          That’s exactly why it should be everywhere.
        </p>

        <p>
          If your API can’t behave correctly at <strong>min</strong> and <strong>max</strong>,
          it doesn’t really have a contract —
          it has a suggestion.
        </p>

        <p>
          Rentgen makes the contract testable by default.
          Because “everyone knows BVA” is not the same thing as actually running it.
        </p>
      </div>
    </article>
  </main>

  <footer class="site-footer">
    <div class="container footer-inner">
      <span>© <span id="year"></span> Rentgen</span>
      <span class="footer-note">Built for testers, by a tester.</span>
    </div>
  </footer>

  <script src="../script.js"></script>
</body>
</html>
